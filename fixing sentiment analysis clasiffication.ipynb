{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>If you are ever in Stockholm, these two museum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Really interesting and so well organised with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>We planned 2 hours for Vasa but it was so inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>It was a very nice experience being there.The ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Travelling with my 11 year old and wanted to d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>This restored shipwreck is absolutely remarkab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2476</td>\n",
       "      <td>This is dedicated to the Vasa only and is very...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>The has to be seen to be believed. It’s massiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>We were in as part of a Scandinavia tour and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2479</td>\n",
       "      <td>This was amazing, and the story of the is very...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  pred_sentiment\n",
       "0     If you are ever in Stockholm, these two museum...               0\n",
       "1     Really interesting and so well organised with ...               1\n",
       "2     We planned 2 hours for Vasa but it was so inte...               0\n",
       "3     It was a very nice experience being there.The ...               1\n",
       "4     Travelling with my 11 year old and wanted to d...               0\n",
       "...                                                 ...             ...\n",
       "2475  This restored shipwreck is absolutely remarkab...               1\n",
       "2476  This is dedicated to the Vasa only and is very...               1\n",
       "2477  The has to be seen to be believed. It’s massiv...               1\n",
       "2478  We were in as part of a Scandinavia tour and t...               1\n",
       "2479  This was amazing, and the story of the is very...               1\n",
       "\n",
       "[2480 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"VasaClean_pred.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>DateOfExperience</th>\n",
       "      <th>DateOfReview</th>\n",
       "      <th>Username</th>\n",
       "      <th>UserLocation</th>\n",
       "      <th>UserContribution</th>\n",
       "      <th>UserLikes</th>\n",
       "      <th>normalized_tweet</th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you are ever in Stockholm, these two museum...</td>\n",
       "      <td>Vasa museum and Nordic museum</td>\n",
       "      <td>50</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>Mar 22</td>\n",
       "      <td>Travelin' Woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ever', 'stockholm', 'two', 'museum', 'right'...</td>\n",
       "      <td>['ever stockholm', 'stockholm two', 'two museu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Really interesting and so well organised with ...</td>\n",
       "      <td>Well worth a visit.</td>\n",
       "      <td>50</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>Mar 18</td>\n",
       "      <td>GoldfinchSuffolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>['well', 'organised', 'enough', 'information',...</td>\n",
       "      <td>['well organised', 'organised enough', 'enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>We planned 2 hours for Vasa but it was so inte...</td>\n",
       "      <td>Awesome swedish history</td>\n",
       "      <td>50</td>\n",
       "      <td>February 2020</td>\n",
       "      <td>Mar 18</td>\n",
       "      <td>Teodora M</td>\n",
       "      <td>Brasov, Romania</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['hour', 'vas', 'interesting', 'forgot', 'leav...</td>\n",
       "      <td>['hour vas', 'vas interesting', 'interesting f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>It was a very nice experience being there.The ...</td>\n",
       "      <td>Vasa Museum-Something Special</td>\n",
       "      <td>40</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>Mar 14</td>\n",
       "      <td>Patsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nice', 'experience', 'huge', 'astonishing', ...</td>\n",
       "      <td>['nice experience', 'experience huge', 'huge a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Travelling with my 11 year old and wanted to d...</td>\n",
       "      <td>Very interesting</td>\n",
       "      <td>40</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>Mar 14</td>\n",
       "      <td>Gavin F</td>\n",
       "      <td>Aberdeen, United Kingdom</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>['year', 'old', 'wanted', 'something', 'ticked...</td>\n",
       "      <td>['year old', 'old wanted', 'wanted something',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>2475</td>\n",
       "      <td>This restored shipwreck is absolutely remarkab...</td>\n",
       "      <td>Should not be missed.</td>\n",
       "      <td>50</td>\n",
       "      <td>September 2018</td>\n",
       "      <td>Sep 2018</td>\n",
       "      <td>alan f</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>['shipwreck', 'absolutely', 'remarkable', 'wor...</td>\n",
       "      <td>['shipwreck absolutely', 'absolutely remarkabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2476</td>\n",
       "      <td>2476</td>\n",
       "      <td>This is dedicated to the Vasa only and is very...</td>\n",
       "      <td>history kept alive</td>\n",
       "      <td>40</td>\n",
       "      <td>August 2018</td>\n",
       "      <td>Sep 2018</td>\n",
       "      <td>STEVE</td>\n",
       "      <td>Lugano, Switzerland</td>\n",
       "      <td>321</td>\n",
       "      <td>47</td>\n",
       "      <td>['dedicated', 'vas', 'well', 'organized', 'wel...</td>\n",
       "      <td>['dedicated vas', 'vas well', 'well organized'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>2477</td>\n",
       "      <td>The has to be seen to be believed. It’s massiv...</td>\n",
       "      <td>Fantastic</td>\n",
       "      <td>50</td>\n",
       "      <td>September 2018</td>\n",
       "      <td>Sep 2018</td>\n",
       "      <td>Penny S</td>\n",
       "      <td>Canberra, Australia</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>['seen', 'believed', 'massive', 'detailed', 'w...</td>\n",
       "      <td>['seen believed', 'believed massive', 'massive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>2478</td>\n",
       "      <td>We were in as part of a Scandinavia tour and t...</td>\n",
       "      <td>Glad we didn't skip this!</td>\n",
       "      <td>50</td>\n",
       "      <td>August 2018</td>\n",
       "      <td>Sep 2018</td>\n",
       "      <td>misc22016</td>\n",
       "      <td>Tigard, Oregon</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>['part', 'scandinavia', 'tour', 'vas', 'made',...</td>\n",
       "      <td>['part scandinavia', 'scandinavia tour', 'tour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2479</td>\n",
       "      <td>2479</td>\n",
       "      <td>This was amazing, and the story of the is very...</td>\n",
       "      <td>So cool!</td>\n",
       "      <td>50</td>\n",
       "      <td>September 2018</td>\n",
       "      <td>Sep 2018</td>\n",
       "      <td>miichelle139</td>\n",
       "      <td>McKinney, Texas</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>['amazing', 'story', 'interesting', 'guided', ...</td>\n",
       "      <td>['amazing story', 'story interesting', 'intere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2480 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text  \\\n",
       "0              0  If you are ever in Stockholm, these two museum...   \n",
       "1              1  Really interesting and so well organised with ...   \n",
       "2              2  We planned 2 hours for Vasa but it was so inte...   \n",
       "3              3  It was a very nice experience being there.The ...   \n",
       "4              4  Travelling with my 11 year old and wanted to d...   \n",
       "...          ...                                                ...   \n",
       "2475        2475  This restored shipwreck is absolutely remarkab...   \n",
       "2476        2476  This is dedicated to the Vasa only and is very...   \n",
       "2477        2477  The has to be seen to be believed. It’s massiv...   \n",
       "2478        2478  We were in as part of a Scandinavia tour and t...   \n",
       "2479        2479  This was amazing, and the story of the is very...   \n",
       "\n",
       "                              Title  Rating DateOfExperience DateOfReview  \\\n",
       "0     Vasa museum and Nordic museum      50       March 2020       Mar 22   \n",
       "1               Well worth a visit.      50       March 2020       Mar 18   \n",
       "2           Awesome swedish history      50    February 2020       Mar 18   \n",
       "3     Vasa Museum-Something Special      40       March 2020       Mar 14   \n",
       "4                  Very interesting      40       March 2020       Mar 14   \n",
       "...                             ...     ...              ...          ...   \n",
       "2475          Should not be missed.      50   September 2018     Sep 2018   \n",
       "2476             history kept alive      40      August 2018     Sep 2018   \n",
       "2477                      Fantastic      50   September 2018     Sep 2018   \n",
       "2478      Glad we didn't skip this!      50      August 2018     Sep 2018   \n",
       "2479                       So cool!      50   September 2018     Sep 2018   \n",
       "\n",
       "              Username              UserLocation UserContribution UserLikes  \\\n",
       "0      Travelin' Woman                       NaN                5       NaN   \n",
       "1     GoldfinchSuffolk                   Suffolk               21        10   \n",
       "2            Teodora M           Brasov, Romania               15       NaN   \n",
       "3                Patsa                       NaN                7       NaN   \n",
       "4              Gavin F  Aberdeen, United Kingdom               91        10   \n",
       "...                ...                       ...              ...       ...   \n",
       "2475            alan f   Los Angeles, California               21         4   \n",
       "2476             STEVE       Lugano, Switzerland              321        47   \n",
       "2477           Penny S       Canberra, Australia               76        13   \n",
       "2478         misc22016            Tigard, Oregon               12         1   \n",
       "2479      miichelle139           McKinney, Texas               34         6   \n",
       "\n",
       "                                       normalized_tweet  \\\n",
       "0     ['ever', 'stockholm', 'two', 'museum', 'right'...   \n",
       "1     ['well', 'organised', 'enough', 'information',...   \n",
       "2     ['hour', 'vas', 'interesting', 'forgot', 'leav...   \n",
       "3     ['nice', 'experience', 'huge', 'astonishing', ...   \n",
       "4     ['year', 'old', 'wanted', 'something', 'ticked...   \n",
       "...                                                 ...   \n",
       "2475  ['shipwreck', 'absolutely', 'remarkable', 'wor...   \n",
       "2476  ['dedicated', 'vas', 'well', 'organized', 'wel...   \n",
       "2477  ['seen', 'believed', 'massive', 'detailed', 'w...   \n",
       "2478  ['part', 'scandinavia', 'tour', 'vas', 'made',...   \n",
       "2479  ['amazing', 'story', 'interesting', 'guided', ...   \n",
       "\n",
       "                                                  grams  \n",
       "0     ['ever stockholm', 'stockholm two', 'two museu...  \n",
       "1     ['well organised', 'organised enough', 'enough...  \n",
       "2     ['hour vas', 'vas interesting', 'interesting f...  \n",
       "3     ['nice experience', 'experience huge', 'huge a...  \n",
       "4     ['year old', 'old wanted', 'wanted something',...  \n",
       "...                                                 ...  \n",
       "2475  ['shipwreck absolutely', 'absolutely remarkabl...  \n",
       "2476  ['dedicated vas', 'vas well', 'well organized'...  \n",
       "2477  ['seen believed', 'believed massive', 'massive...  \n",
       "2478  ['part scandinavia', 'scandinavia tour', 'tour...  \n",
       "2479  ['amazing story', 'story interesting', 'intere...  \n",
       "\n",
       "[2480 rows x 12 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/Users/maxrojas/Desktop/BI/3period/datasets/VasaClean.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_col = pd.merge(df, df2, on='Text')\n",
    "df_merge_col = df_merge_col.drop(columns=\"Unnamed: 0\")\n",
    "pos = df_merge_col[df_merge_col.pred_sentiment == 1]\n",
    "neg = df_merge_col[df_merge_col.pred_sentiment == 0]\n",
    "\n",
    "pos.to_csv('VasaPosFinal.csv')\n",
    "neg.to_csv('VasaNegFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>If you are ever in Stockholm, these two museum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Really interesting and so well organised with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>We planned 2 hours for Vasa but it was so inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>It was a very nice experience being there.The ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Travelling with my 11 year old and wanted to d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>This restored shipwreck is absolutely remarkab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2476</td>\n",
       "      <td>This is dedicated to the Vasa only and is very...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>The has to be seen to be believed. It’s massiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>We were in as part of a Scandinavia tour and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2479</td>\n",
       "      <td>This was amazing, and the story of the is very...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  pred_sentiment\n",
       "0     If you are ever in Stockholm, these two museum...               0\n",
       "1     Really interesting and so well organised with ...               1\n",
       "2     We planned 2 hours for Vasa but it was so inte...               0\n",
       "3     It was a very nice experience being there.The ...               1\n",
       "4     Travelling with my 11 year old and wanted to d...               0\n",
       "...                                                 ...             ...\n",
       "2475  This restored shipwreck is absolutely remarkab...               1\n",
       "2476  This is dedicated to the Vasa only and is very...               1\n",
       "2477  The has to be seen to be believed. It’s massiv...               1\n",
       "2478  We were in as part of a Scandinavia tour and t...               1\n",
       "2479  This was amazing, and the story of the is very...               1\n",
       "\n",
       "[2480 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Text','pred_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary:  1480\n",
      "10 most informative features: \n",
      "Most Informative Features\n",
      "                      iq = True                1 : 0      =     41.7 : 1.0\n",
      "                     bam = True                1 : 0      =     29.7 : 1.0\n",
      "                      wi = True                0 : 1      =     25.0 : 1.0\n",
      "                     sad = True                0 : 1      =     21.9 : 1.0\n",
      "                   horan = True                1 : 0      =     17.8 : 1.0\n",
      "                     ugh = True                0 : 1      =     17.7 : 1.0\n",
      "                    glad = True                1 : 0      =     17.4 : 1.0\n",
      "               goodnight = True                1 : 0      =     16.3 : 1.0\n",
      "                opportun = True                1 : 0      =     15.7 : 1.0\n",
      "                   arriv = True                1 : 0      =     15.0 : 1.0\n",
      "None\n",
      "Training completed\n",
      "confusion matrix\n",
      "[[4270  730]\n",
      " [1331 3669]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81      5000\n",
      "           1       0.83      0.73      0.78      5000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "File being processed:  AbbaClean.csv\n",
      "1    3705\n",
      "0     848\n",
      "Name: pred_sentiment, dtype: int64\n",
      "(4553, 12)\n",
      "File being processed:  CityHallClean.csv\n",
      "1    1582\n",
      "0     235\n",
      "Name: pred_sentiment, dtype: int64\n",
      "(1817, 14)\n",
      "File being processed:  DjugardenClean.csv\n",
      "1    890\n",
      "0    132\n",
      "Name: pred_sentiment, dtype: int64\n",
      "(1022, 12)\n",
      "File being processed:  GamlaStanClean.csv\n",
      "1    5529\n",
      "0    1394\n",
      "Name: pred_sentiment, dtype: int64\n",
      "(6923, 12)\n",
      "File being processed:  VasaClean.csv\n",
      "1    2049\n",
      "0     431\n",
      "Name: pred_sentiment, dtype: int64\n",
      "(2480, 14)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import re\n",
    "from nltk.corpus import twitter_samples\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# df = pd.read_csv(\"data/sentiment140/training.1600000.processed.noemoticon.csv\", engine='python')\n",
    "\n",
    "# tokenize text\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "# remove punctuations apostrophies and special characters to ensure small/ relevant vocab\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"http\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# remove stopwords to reduce vocabulary size\n",
    "def remove_stopwords(text):\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in text if not word in stop_words]\n",
    "\n",
    "# stem text to ensure different variations of same words are treated in a similar manner\n",
    "def stemmer(text):\n",
    "    stemm = nltk.stem.PorterStemmer()\n",
    "    return  [stemm.stem(word) for word in text]\n",
    "\n",
    "# stem text to ensure different variations of same words are treated in a similar manner\n",
    "def lemmatize(text):\n",
    "    lem = nltk.stem.WordNetLemmatizer()\n",
    "    return  [lem.lemmatize(word) for word in text]\n",
    "\n",
    "# pipeline to work on the text\n",
    "def text_pipeline(text):\n",
    "    text = clean_text(text)\n",
    "    text = tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemmer(text)\n",
    "    text = lemmatize(text)\n",
    "    return text\n",
    "\n",
    "# get vocabulary for a given training data\n",
    "def get_vocabulary(freq_dist, cutoff=None):\n",
    "    if cutoff == None:\n",
    "        return [key for key in freq_dist.keys()]\n",
    "    else:\n",
    "        d = []\n",
    "        for k in freq_dist.keys():\n",
    "            if freq_dist[k] > cutoff:\n",
    "                d.append(k)\n",
    "        return d\n",
    "\n",
    "# process text and get features using the vocabulary indicating presence or absence of words in text\n",
    "def get_features(text, vocab):\n",
    "    text_processed = text_pipeline(text)\n",
    "    return {word: (word in text_processed) for word in vocab}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load training data\n",
    "    positive_tweets = pd.DataFrame(twitter_samples.strings('positive_tweets.json'), columns=['text'])\n",
    "    negative_tweets = pd.DataFrame(twitter_samples.strings('negative_tweets.json'), columns=['text'])\n",
    "\n",
    "    # assign label positive as 1 and negative as 0\n",
    "    positive_tweets['label'] = 1\n",
    "    negative_tweets['label'] = 0\n",
    "\n",
    "    # combine to get the complete training dataset\n",
    "    df = pd.concat([positive_tweets, negative_tweets], axis=0, sort=False)\n",
    "\n",
    "    # get frequency distribution o words for the entire training data\n",
    "    word_feat = FreqDist(chain(*[text_pipeline(text) for text in df['text'].values]))\n",
    "\n",
    "    # put only words with freq > 5 in the vocabulary\n",
    "    vocabulary = get_vocabulary(word_feat, 5)\n",
    "    print(\"Length of vocabulary: \", len(vocabulary))\n",
    "\n",
    "    # get features for each sentence in the dataset\n",
    "    df['feat'] = df['text'].apply(lambda x: get_features(x, vocabulary))\n",
    "\n",
    "    # get tuple using dictionary and label\n",
    "    df['train_data']= df[['feat', 'label']].apply(tuple, axis=1)\n",
    "\n",
    "    # train classifier\n",
    "    df['pred_sentiment'] = 0\n",
    "    classifier = NaiveBayesClassifier.train(df['train_data'].values)\n",
    "    df['pred_sentiment'] = df['feat'].apply(classifier.classify)\n",
    "\n",
    "    print(\"10 most informative features: \")\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "\n",
    "    df[['text', 'pred_sentiment']].to_csv(\"check.csv\", index=False)\n",
    "    print(\"Training completed\")\n",
    "\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(df['label'], df['pred_sentiment']))\n",
    "\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(df['label'], df['pred_sentiment']))\n",
    "\n",
    "    # iterate through filenames\n",
    "    test_filenames = ['AbbaClean.csv', 'CityHallClean.csv', 'DjugardenClean.csv', 'GamlaStanClean.csv', 'VasaClean.csv']\n",
    "\n",
    "\n",
    "    for filename in test_filenames:\n",
    "        print(\"File being processed: \", filename)\n",
    "        # load filename\n",
    "        data = pd.read_csv(filename)\n",
    "        # get features for each line in the test dataset\n",
    "        data['feat'] = data['Text'].apply(lambda x: get_features(x, vocabulary))\n",
    "        # store predicted sentiment and save as a csv file\n",
    "        data['pred_sentiment'] = 0\n",
    "        data['pred_sentiment'] = data['feat'].apply(classifier.classify)\n",
    "        print(data['pred_sentiment'].value_counts())\n",
    "        print(data.shape)\n",
    "        data[['Text', 'pred_sentiment']].to_csv(filename.split(\".\")[0] + \"_pred.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
